{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3baa2f",
   "metadata": {},
   "source": [
    "Create the SparkSession and set the environment to use our local MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cccd78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook2\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        config(\"spark.mongodb.input.uri\",\"mongodb://mongo1:27017,mongo2:27018,mongo3:27019/Stocks.Source?replicaSet=rs0\").\\\n",
    "        config(\"spark.mongodb.output.uri\",\"mongodb://mongo1:27017,mongo2:27018,mongo3:27019/Stocks.Source?replicaSet=rs0\").\\\n",
    "        config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf6468",
   "metadata": {},
   "source": [
    "Next load the dataframes from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3bdb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355d4a9",
   "metadata": {},
   "source": [
    "Let’s verify the data was loaded by looking at the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adc2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- company_symbol: string (nullable = true)\n",
      " |-- movingAverage: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- tx_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99c226",
   "metadata": {},
   "source": [
    "We can see that the tx_time field is loaded as a string. We can easily convert this to a time by issuing a cast statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc240d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"tx_time\", df.tx_time.cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a1d44",
   "metadata": {},
   "source": [
    "Next, we can add a new ‘movingAverage’ column that will show a moving average based upon the previous value in the dataset. To do this we leverage the PySpark Window function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4cb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "movAvg = df.withColumn(\"movingAverage\", F.avg(\"price\")\n",
    "             .over( Window.partitionBy(\"company_symbol\").rowsBetween(-1,1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d0957",
   "metadata": {},
   "source": [
    "To see our data with the new moving average column we can issue a movAvg.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597ba24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "|                 _id|        company_name|company_symbol|     movingAverage|price|            tx_time|\n",
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "|[5f527ac22f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.385000000000005|43.38|2020-09-04 13:34:58|\n",
      "|[5f527ac32f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.39666666666667|43.39|2020-09-04 13:34:59|\n",
      "|[5f527ac42f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.419999999999995|43.42|2020-09-04 13:35:00|\n",
      "|[5f527ac52f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.443333333333335|43.45|2020-09-04 13:35:01|\n",
      "|[5f527ac62f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.46|43.46|2020-09-04 13:35:02|\n",
      "|[5f527ac72f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.49|43.47|2020-09-04 13:35:03|\n",
      "|[5f527aca2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.51|43.54|2020-09-04 13:35:06|\n",
      "|[5f527ac92f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.52|2020-09-04 13:35:05|\n",
      "|[5f527acd2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.53|2020-09-04 13:35:09|\n",
      "|[5f527acf2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.54|2020-09-04 13:35:11|\n",
      "|[5f527ad22f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.51|43.52|2020-09-04 13:35:14|\n",
      "|[5f527ad42f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.49666666666667|43.47|2020-09-04 13:35:16|\n",
      "|[5f527ad62f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.48666666666667| 43.5|2020-09-04 13:35:18|\n",
      "|[5f527ad82f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.473333333333336|43.49|2020-09-04 13:35:20|\n",
      "|[5f527ada2f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.42666666666667|43.43|2020-09-04 13:35:22|\n",
      "|[5f527adc2f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.373333333333335|43.36|2020-09-04 13:35:24|\n",
      "|[5f527ade2f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.32333333333333|43.33|2020-09-04 13:35:26|\n",
      "|[5f527ae02f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.303333333333335|43.28|2020-09-04 13:35:28|\n",
      "|[5f527ae22f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.29333333333333| 43.3|2020-09-04 13:35:30|\n",
      "|[5f527ae42f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.31| 43.3|2020-09-04 13:35:32|\n",
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movAvg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de797f",
   "metadata": {},
   "source": [
    "To update the data in our MongoDB cluster, we use the save method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad764377",
   "metadata": {},
   "outputs": [],
   "source": [
    "movAvg.write.format(\"mongo\").option(\"replaceDocument\", \"true\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032b1cb",
   "metadata": {},
   "source": [
    "We can also use the power of the MongoDB Aggregation Framework to pre-filter, sort or aggregate our MongoDB data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56493258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                 _id|maxprice|\n",
      "+--------------------+--------+\n",
      "|FRUSTRATING CHAOS...|    87.6|\n",
      "|HOMELY KIOSK UNLI...|   86.48|\n",
      "| CREEPY GIT HOLDINGS|    83.4|\n",
      "|GREASY CHAMPION C...|   81.76|\n",
      "|COMBATIVE TOWNSHI...|   72.18|\n",
      "|FROTHY MIDNIGHT P...|   66.81|\n",
      "|ITCHY ACRE CORPOR...|   44.42|\n",
      "|LACKADAISICAL SAV...|   42.34|\n",
      "|CORNY PRACTITIONE...|   38.55|\n",
      "|TRITE JACKFRUIT P...|   22.62|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = \"[{'$group': {_id:'$company_name', 'maxprice': {$max:'$price'}}},{$sort:{'maxprice':-1}}]\"\n",
    "aggPipelineDF = spark.read.format(\"mongo\").option(\"pipeline\", pipeline).option(\"partitioner\", \"MongoSinglePartitioner\").load()\n",
    "aggPipelineDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77919d",
   "metadata": {},
   "source": [
    "Finally we can use SparkSQL to issue ANSI-compliant SQL against MongoDB data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a528614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "|                 _id|        company_name|company_symbol|     movingAverage|price|            tx_time|\n",
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "|[5f527ac22f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.385000000000005|43.38|2020-09-04 13:34:58|\n",
      "|[5f527ac32f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.39666666666667|43.39|2020-09-04 13:34:59|\n",
      "|[5f527ac42f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.419999999999995|43.42|2020-09-04 13:35:00|\n",
      "|[5f527ac52f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.443333333333335|43.45|2020-09-04 13:35:01|\n",
      "|[5f527ac62f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.46|43.46|2020-09-04 13:35:02|\n",
      "|[5f527ac72f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.49|43.47|2020-09-04 13:35:03|\n",
      "|[5f527aca2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.51|43.54|2020-09-04 13:35:06|\n",
      "|[5f527ac92f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.52|2020-09-04 13:35:05|\n",
      "|[5f527acd2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.53|2020-09-04 13:35:09|\n",
      "|[5f527acf2f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.53|43.54|2020-09-04 13:35:11|\n",
      "|[5f527ad22f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.51|43.52|2020-09-04 13:35:14|\n",
      "|[5f527ad42f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.49666666666667|43.47|2020-09-04 13:35:16|\n",
      "|[5f527ad62f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.48666666666667| 43.5|2020-09-04 13:35:18|\n",
      "|[5f527ad82f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.473333333333336|43.49|2020-09-04 13:35:20|\n",
      "|[5f527ada2f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.42666666666667|43.43|2020-09-04 13:35:22|\n",
      "|[5f527adc2f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.373333333333335|43.36|2020-09-04 13:35:24|\n",
      "|[5f527ade2f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.32333333333333|43.33|2020-09-04 13:35:26|\n",
      "|[5f527ae02f6a1552...|ITCHY ACRE CORPOR...|           IAC|43.303333333333335|43.28|2020-09-04 13:35:28|\n",
      "|[5f527ae22f6a1552...|ITCHY ACRE CORPOR...|           IAC| 43.29333333333333| 43.3|2020-09-04 13:35:30|\n",
      "|[5f527ae42f6a1552...|ITCHY ACRE CORPOR...|           IAC|             43.31| 43.3|2020-09-04 13:35:32|\n",
      "+--------------------+--------------------+--------------+------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movAvg.createOrReplaceTempView(\"avgs\")\n",
    "sqlDF=spark.sql(\"SELECT * FROM avgs WHERE movingAverage > 43.0\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3f879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
